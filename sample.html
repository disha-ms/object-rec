<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8 Object Detection System</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'forest' });
    </script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);
            color: #f0f8ff;
            padding: 20px;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            text-align: center;
            margin-bottom: 40px;
            padding: 20px;
            background: rgba(16, 44, 54, 0.8);
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
        }
        
        h1 {
            font-size: 2.8rem;
            margin-bottom: 15px;
            color: #7fffd4;
            text-shadow: 0 2px 5px rgba(0, 0, 0, 0.5);
        }
        
        h2 {
            font-size: 2rem;
            margin: 30px 0 20px;
            color: #7fffd4;
            border-bottom: 2px solid #5f9ea0;
            padding-bottom: 10px;
        }
        
        p {
            font-size: 1.1rem;
            margin-bottom: 20px;
        }
        
        .card {
            background: rgba(16, 44, 54, 0.8);
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
        }
        
        .diagram {
            background: white;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            overflow-x: auto;
        }
        
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
        }
        
        .features {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
        }
        
        .feature {
            background: rgba(25, 60, 70, 0.8);
            border-radius: 10px;
            padding: 20px;
            flex: 1 1 300px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .feature h3 {
            color: #7fffd4;
            margin-bottom: 15px;
        }
        
        .feature-icon {
            font-size: 2.5rem;
            margin-bottom: 15px;
            color: #5f9ea0;
        }
        
        footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #a9a9a9;
        }
        
        @media (max-width: 768px) {
            h1 {
                font-size: 2.2rem;
            }
            
            h2 {
                font-size: 1.8rem;
            }
            
            .container {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>YOLOv8 Object Detection System</h1>
            <p>Real-time object identification using YOLOv8 and OpenCV</p>
        </header>
        
        <div class="card">
            <h2>System Overview</h2>
            <p>This system uses YOLOv8 (You Only Look Once version 8) for real-time object detection through a webcam feed. It can identify and label 80 different classes of common objects with bounding boxes and confidence scores.</p>
            
            <div class="features">
                <div class="feature">
                    <div class="feature-icon">üì∑</div>
                    <h3>Webcam Capture</h3>
                    <p>Captures live video feed from your webcam using OpenCV</p>
                </div>
                <div class="feature">
                    <div class="feature-icon">ü§ñ</div>
                    <h3>YOLOv8 Model</h3>
                    <p>Pre-trained on COCO dataset for 80-class object detection</p>
                </div>
                <div class="feature">
                    <div class="feature-icon">üîç</div>
                    <h3>Real-time Processing</h3>
                    <p>Processes each frame and displays results in real-time</p>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>System Architecture</h2>
            <p>The architecture of the YOLOv8 object detection system showing the flow of data and processing steps:</p>
            
            <div class="diagram">
                <div class="mermaid">
                    flowchart TD
                    A[Webcam Video Input] --> B(Capture Frame)
                    B --> C(Preprocess Frame)
                    C --> D{YOLOv8 Model}
                    D --> E(Predict Objects)
                    E --> F(Post-process Results)
                    F --> G(Draw Bounding Boxes)
                    G --> H(Display Annotated Frame)
                    H --> I{Exit Condition?}
                    I -- No --> B
                    I -- Yes --> J(Release Resources)
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>Implementation Code</h2>
            <p>The Python code that implements the YOLOv8 object detection system:</p>
            
            <div class="code-block">
                <pre><code>import cv2
from ultralytics import YOLO

# Load a pre-trained YOLOv8 model (detects 80 common objects)
model = YOLO("yolov8n.pt")

# Open laptop webcam
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Run YOLO detection
    results = model(frame, stream=True)

    for r in results:
        for box in r.boxes:
            # Extract coordinates
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])  # confidence
            cls = int(box.cls[0])      # class id
            label = model.names[cls]   # class name
            
            # Draw rectangle & label
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
            cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
    
    cv2.imshow("Object Identification", frame)

    # Exit on 'q' key
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# cleanup (only runs after loop breaks)
cap.release()
cv2.destroyAllWindows()</code></pre>
            </div>
        </div>
        
        <div class="card">
            <h2>Detailed Process Flow</h2>
            <p>The complete workflow of the object detection system from initialization to cleanup:</p>
            
            <div class="diagram">
                <div class="mermaid">
                    flowchart LR
                    A[Start] --> B[Import Libraries]
                    B --> C[Load YOLOv8 Model]
                    C --> D[Initialize Webcam]
                    D --> E{Capture Frame}
                    E -- Success --> F[Run YOLO Detection]
                    E -- Fail --> K[End Program]
                    F --> G[Process Detection Results]
                    G --> H[Draw Bounding Boxes & Labels]
                    H --> I[Display Annotated Frame]
                    I --> J{Press 'q' to quit?}
                    J -- No --> E
                    J -- Yes --> K
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>Confusion Matrix</h2>
            <p>A confusion matrix is a performance measurement for machine learning classification problems. It shows how well the model is predicting by comparing actual vs predicted values.</p>
            
            <div class="diagram">
                <div class="mermaid">
                    quadrantChart
                    title Confusion Matrix for Object Detection
                    x-axis "Predicted Class" --> "Negative" "Positive"
                    y-axis "Actual Class" --> "Positive" "Negative"
                    "True Positive (TP)": [0.7, 0.7]
                    "False Negative (FN)": [0.2, 0.7]
                    "False Positive (FP)": [0.7, 0.2]
                    "True Negative (TN)": [0.2, 0.2]
                </div>
            </div>
            
            <p><strong>Explanation:</strong></p>
            <ul>
                <li><strong>True Positive (TP):</strong> Object correctly detected as present</li>
                <li><strong>False Positive (FP):</strong> Object detected but not actually present (false alarm)</li>
                <li><strong>True Negative (TN):</strong> No object detected when no object present (correct rejection)</li>
                <li><strong>False Negative (FN):</strong> Object present but not detected (missed detection)</li>
            </ul>
        </div>
        
        <div class="card">
            <h2>Performance Metrics</h2>
            <p>Key metrics derived from the confusion matrix to evaluate object detection performance:</p>
            
            <div class="diagram">
                <div class="mermaid">
                    graph LR
                    A[Confusion Matrix] --> B[Precision: TP / (TP + FP)]
                    A --> C[Recall: TP / (TP + FN)]
                    A --> D[Accuracy: (TP + TN) / Total]
                    B --> E(F1 Score: 2 * Precision * Recall / (Precision + Recall))
                    C --> E
                </div>
            </div>
        </div>
        
        <footer>
            <p>YOLOv8 Object Detection System | Created with Mermaid.js</p>
        </footer>
    </div>
</body>
</html>